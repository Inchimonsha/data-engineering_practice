{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e606acd",
   "metadata": {},
   "source": [
    "## Создание и хранение embedding-векторов\n",
    "\n",
    "Задача: Создать таблицу с колонкой типа VECTOR(dimensions) для хранения embedding-векторов (например, размерность 1536 для моделей OpenAI).\n",
    "\n",
    "Добавить несколько записей с векторами и проверить, как PostgreSQL хранит и отображает эти данные.\n",
    "\n",
    "Цель: понять, как устроен тип данных VECTOR и как с ним работать в SQL.\n",
    "\n",
    "Пример:\n",
    "\n",
    "sql\n",
    "CREATE TABLE items (\n",
    "id SERIAL PRIMARY KEY,\n",
    "title TEXT,\n",
    "embedding VECTOR(1536)\n",
    ");\n",
    "INSERT INTO items (title, embedding) VALUES\n",
    "('Example 1', '[0.1, -0.8, 0.45, ...]'), \n",
    "('Example 2', '[0.42, 0.18, -0.35, ...]');\n",
    "\n",
    "## Поиск ближайших соседей (nearest neighbor search)\n",
    "\n",
    "Задача: Реализовать поиск элементов, embedding-которые наиболее близки к заданному вектору.\n",
    "\n",
    "Использовать встроенные операторы расстояний: Евклидово расстояние (<->), косинусное расстояние (<=>) и внутренний продукт (<#>).\n",
    "\n",
    "Сделать SQL-запрос, который находит, например, 5 ближайших соседей по embedding.\n",
    "\n",
    "Цель: научиться использовать операторы векторного поиска и индексировать векторы.\n",
    "\n",
    "Пример:\n",
    "\n",
    "sql\n",
    "SELECT id, title\n",
    "FROM items\n",
    "ORDER BY embedding <-> '[0.12, -0.82, 0.44, ...]'\n",
    "LIMIT 5;\n",
    "\n",
    "## Добавление и использование индексов для ускорения поиска\n",
    "\n",
    "Задача: Создать индексы типа ivfflat или hnsw на колонку с векторами, чтобы ускорить поиск ближайших соседей.\n",
    "\n",
    "Проверить скорость выполнения запросов с и без индекса на больших наборах данных.\n",
    "\n",
    "Цель: понять, как работать с индексами в pgvector, их настройками и ограничениями.\n",
    "\n",
    "Пример создания индекса:\n",
    "\n",
    "sql\n",
    "CREATE INDEX ON items USING ivfflat (embedding vector_l2_ops) WITH (lists = 100);\n",
    "\n",
    "## Реализация рекомендательной системы\n",
    "\n",
    "Задача: На основе векторных представлений товаров реализовать рекомендации похожих товаров.\n",
    "\n",
    "Пользователь выбирает один товар — нужно найти и вернуть список других товаров с наиболее похожими embedding.\n",
    "\n",
    "Цель: отработать полный цикл: получение embedding, сохранение, поиск и выдача рекомендаций.\n",
    "\n",
    "Можно усложнить, добавив дополнительную фильтрацию по категориям или цене.\n",
    "\n",
    "## Семантический поиск по тексту с использованием embedding\n",
    "\n",
    "Задача: Создать базу знаний, где документы хранятся вместе с embedding их содержимого.\n",
    "\n",
    "При поисковом запросе текст переводится в embedding через внешнюю модель (OpenAI, HuggingFace), после чего выполняется поиск ближайших документов по векторному сходству в pgvector.\n",
    "\n",
    "Цель: реализовать простой RAG (retrieval-augmented generation) или semantic search MVP с минимальной архитектурой.\n",
    "\n",
    "Можно написать Python-скрипт для вычисления embedding и записи/поиска в базе.\n",
    "\n",
    "## Кластеризация и анализ embedding в базе\n",
    "\n",
    "Задача: Использовать pgvector для выборки embedding, последующего кластерного анализа (например, DBSCAN) на стороне клиента или в интеграции с PL/Python.\n",
    "\n",
    "Цель: понимать возможности pgvector для аналитики векторных данных.\n",
    "\n",
    "## Обработка мультимодальных данных\n",
    "\n",
    "Задача: хранение и поиск embedding для изображений, текста и аудио в одной базе с помощью pgvector.\n",
    "\n",
    "Реализовать поиск по нескольким видам embedding, сравнивая их и объединяя результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "351a17ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xc2 in position 61: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpsycopg2\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m conn = \u001b[43mpsycopg2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdbname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43megamedb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43madmin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43madmin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlocalhost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mport\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m5432\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mСоединение установлено!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\main\\data_science\\projects\\ml_practice\\.venv\\Lib\\site-packages\\psycopg2\\__init__.py:135\u001b[39m, in \u001b[36mconnect\u001b[39m\u001b[34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[39m\n\u001b[32m    132\u001b[39m     kwasync[\u001b[33m'\u001b[39m\u001b[33masync_\u001b[39m\u001b[33m'\u001b[39m] = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33masync_\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    134\u001b[39m dsn = _ext.make_dsn(dsn, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m conn = \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    137\u001b[39m     conn.cursor_factory = cursor_factory\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0xc2 in position 61: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"egamedb\",\n",
    "    user=\"admin\",\n",
    "    password=\"admin\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "print(\"Соединение установлено!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba2422e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
