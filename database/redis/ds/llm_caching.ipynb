{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337b1bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "import hashlib\n",
    "from typing import Dict, Any, List\n",
    "from redis.asyncio import Redis\n",
    "from redisvl.extensions.cache.llm import SemanticCache\n",
    "from redisvl.utils.vectorize import HFTextVectorizer\n",
    "from langchain_openai import ChatOpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import msgpack\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca65219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b526abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:45:13 sentence_transformers.SentenceTransformer INFO   Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "20:45:16 redisvl.index.index INFO   Index already exists, not overwriting.\n",
      "20:45:16 redisvl.utils.vectorize.base WARNING   This vectorizer has no async embed method. Falling back to sync.\n",
      "{'entry_id': 'c60b06d91e39e3f8df14a5e99049585be889279752ce0ed3a50186079e2b2737', 'prompt': 'user: –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç Python async/await?', 'response': '`async` –∏ `await` –≤ Python –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–º –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ–º, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤–≤–æ–¥–∞-–≤—ã–≤–æ–¥–∞ (I/O) –±–µ–∑ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è. –≠—Ç–æ –æ—Å–æ–±–µ–Ω–Ω–æ –ø–æ–ª–µ–∑–Ω–æ –¥–ª—è –∑–∞–¥–∞—á, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –∑–∞–Ω—è—Ç—å –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏, —Ç–∞–∫–∏—Ö –∫–∞–∫ —Å–µ—Ç–µ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –∏–ª–∏ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å —Ñ–∞–π–ª–∞–º–∏.\\n\\n### –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏\\n\\n1. **–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏**:\\n   –§—É–Ω–∫—Ü–∏–∏, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞ `async`, —è–≤–ª—è—é—Ç—Å—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–º–∏. –û–Ω–∏ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç –æ–±—ä–µ–∫—Ç —Ç–∏–ø–∞ `coroutine`, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å —Å –ø–æ–º–æ—â—å—é `await`.\\n\\n   ```python\\n   async def my_coroutine():\\n       print(\"Start\")\\n       await asyncio.sleep(1)  # –ò–º–∏—Ç–∞—Ü–∏—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –æ–ø–µ—Ä–∞—Ü–∏–∏\\n       print(\"End\")\\n   ```\\n\\n2. **–û–∂–∏–¥–∞–Ω–∏–µ (await)**:\\n   –ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ `await` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–∂–∏–¥–∞–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∫–æ—Ä—É—Ç–∏–Ω—ã. –ö–æ–≥–¥–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–æ—Ö–æ–¥–∏—Ç –¥–æ `await`, —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –æ–±—Ä–∞—Ç–Ω–æ –≤ —Ü–∏–∫–ª —Å–æ–±—ã—Ç–∏–π, –ø–æ–∑–≤–æ–ª—è—è –¥—Ä—É–≥–∏–º –∑–∞–¥–∞—á–∞–º –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è, –ø–æ–∫–∞ –æ–∂–∏–¥–∞–µ–º–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è –Ω–µ –∑–∞–≤–µ—Ä—à–∏—Ç—Å—è.\\n\\n   ```python\\n   async def main():\\n       await my_coroutine()\\n   ```\\n\\n3. **–¶–∏–∫–ª —Å–æ–±—ã—Ç–∏–π**:\\n   –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏ –∫–æ—Ä—É—Ç–∏–Ω—ã –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Ü–∏–∫–ª–∞ —Å–æ–±—ã—Ç–∏–π, –∫–æ—Ç–æ—Ä—ã–π —É–ø—Ä–∞–≤–ª—è–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á. –í Python –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–º –∫–æ–¥–æ–º –æ–±—ã—á–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥—É–ª—å `asyncio`.\\n\\n   ```python\\n   import asyncio\\n\\n   asyncio.run(main())\\n   ```\\n\\n### –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\\n\\n–í–æ—Ç –ø—Ä–∏–º–µ—Ä, –∫–æ—Ç–æ—Ä—ã–π –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç, –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `async` –∏ `await` –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á:\\n\\n```python\\nimport asyncio\\n\\nasync def fetch_data(delay):\\n    print(f\"Fetching data with delay {delay} seconds...\")\\n    await asyncio.sleep(delay)\\n    print(f\"Data fetched after {delay} seconds!\")\\n    return f\"Data {delay}\"\\n\\nasync def main():\\n    # –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–æ—Ä—É—Ç–∏–Ω –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ\\n    tasks = [\\n        fetch_data(2),\\n        fetch_data(1),\\n        fetch_data(3)\\n    ]\\n    results = await asyncio.gather(*tasks)\\n    print(\"All data fetched:\", results)\\n\\n# –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Å–æ–±—ã—Ç–∏–π\\nasyncio.run(main())\\n```\\n\\n### –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–∞\\n\\n1. **fetch_data**: –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è –∏–º–∏—Ç–∏—Ä—É–µ—Ç –∑–∞–¥–µ—Ä–∂–∫—É —Å –ø–æ–º–æ—â—å—é `asyncio.sleep()`.\\n2. **main**: –û—Å–Ω–æ–≤–Ω–∞—è –∫–æ—Ä—É—Ç–∏–Ω–∞, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–∑–¥–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç `asyncio.gather()` –¥–ª—è –∏—Ö –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è.\\n3. **asyncio.run(main())**: –ó–∞–ø—É—Å–∫–∞–µ—Ç —Ü–∏–∫–ª —Å–æ–±—ã—Ç–∏–π –∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∫–æ—Ä—É—Ç–∏–Ω—É `main`.\\n\\n### –ó–∞–∫–ª—é—á–µ–Ω–∏–µ\\n\\n–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ `async` –∏ `await` –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–∏—Å–∞—Ç—å –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –∏ —á–∏—Ç–∞–µ–º—ã–π –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –º–Ω–æ–∂–µ—Å—Ç–≤–æ –æ–ø–µ—Ä–∞—Ü–∏–π –≤–≤–æ–¥–∞-–≤—ã–≤–æ–¥–∞ –±–µ–∑ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã. –≠—Ç–æ –æ—Å–æ–±–µ–Ω–Ω–æ –ø–æ–ª–µ–∑–Ω–æ –≤ –≤–µ–±-—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ, —Å–µ—Ç–µ–≤–æ–º –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏ –¥—Ä—É–≥–∏—Ö –æ–±–ª–∞—Å—Ç—è—Ö, –≥–¥–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–º.', 'vector_distance': 1.0, 'inserted_at': 1764429296.41, 'updated_at': 1764429296.41, 'key': 'llm_semantic_cache:c60b06d91e39e3f8df14a5e99049585be889279752ce0ed3a50186079e2b2737'}\n",
      "‚úÖ SEMANTIC HIT: `async` –∏ `await` –≤ Python –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è —Ä–∞–±–æ—Ç—ã...\n",
      "dict_keys(['entry_id', 'prompt', 'response', 'vector_distance', 'inserted_at', 'updated_at', 'key'])\n",
      "Q1: `async` –∏ `await` –≤ Python –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–º –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ–º, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –≤—ã...\n",
      "20:45:16 redisvl.utils.vectorize.base WARNING   This vectorizer has no async embed method. Falling back to sync.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 103\u001b[39m\n\u001b[32m    100\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mQ\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m'\u001b[39m][:\u001b[32m100\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    101\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio.sleep(\u001b[32m0.1\u001b[39m)  \u001b[38;5;66;03m# Rate limit\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m test_semantic_cache()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 98\u001b[39m, in \u001b[36mtest_semantic_cache\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(queries):\n\u001b[32m     97\u001b[39m     messages = [{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: q}]\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m cache.get_or_generate(messages)\n\u001b[32m     99\u001b[39m     \u001b[38;5;28mprint\u001b[39m(result.keys())\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mQ\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m'\u001b[39m][:\u001b[32m100\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36mSemanticLLMCache.get_or_generate\u001b[39m\u001b[34m(self, messages, **kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m prompt_text = \u001b[38;5;28mself\u001b[39m._normalize_prompt(messages)\n\u001b[32m     45\u001b[39m cached = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.semantic_cache.acheck(prompt_text)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m cached = \u001b[43mcached\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cached:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28mprint\u001b[39m(cached)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "class SemanticLLMCache:\n",
    "    def __init__(self, redis_url: str, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        self.redis = Redis.from_url(redis_url)\n",
    "        self.embedder = HFTextVectorizer(\n",
    "            model=model_name, \n",
    "            device=\"cpu\"  # GPU –¥–ª—è prod\n",
    "        )\n",
    "        \n",
    "        # ‚úÖ RedisVL SemanticCache (state-of-the-art 2025)\n",
    "        self.semantic_cache = SemanticCache(\n",
    "            name=\"llm_semantic_cache\",\n",
    "            redis_url=redis_url,\n",
    "            distance_threshold=0.85,  # 85% —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å = HIT\n",
    "            vectorizer=self.embedder,\n",
    "            redis_embedding_namespace=\"semantic_embeddings\"\n",
    "        )\n",
    "        \n",
    "        self.llm = ChatOpenAI(\n",
    "            base_url=\"https://openrouter.ai/api/v1\",\n",
    "            api_key=OPENROUTER_API_KEY,\n",
    "            model=\"grok-beta\",\n",
    "            temperature=0.1\n",
    "        )\n",
    "    \n",
    "    async def get_or_generate(\n",
    "        self, \n",
    "        messages: List[Dict[str, str]], \n",
    "        **kwargs\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ + fallback –Ω–∞ exact match\"\"\"\n",
    "        \n",
    "        # 1. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫\n",
    "        prompt_text = self._normalize_prompt(messages)\n",
    "        cached = await self.semantic_cache.acheck(prompt_text)\n",
    "        cached = cached[0]\n",
    "        \n",
    "        if cached:\n",
    "            print(cached)\n",
    "            print(f\"‚úÖ SEMANTIC HIT: {cached['response'][:50]}...\")\n",
    "            return cached\n",
    "        \n",
    "        # 2. Exact match fallback (SHA256)\n",
    "        exact_key = self._make_exact_key(messages, **kwargs)\n",
    "        exact_cached = await self._exact_cache_get(exact_key)\n",
    "        if exact_cached:\n",
    "            print(f\"‚úÖ EXACT HIT: {exact_key[:16]}...\")\n",
    "            return exact_cached\n",
    "        \n",
    "        # 3. LLM –≤—ã–∑–æ–≤\n",
    "        print(\"üîÑ MISS ‚Üí LLM...\")\n",
    "        response = await self.llm.ainvoke(messages, **kwargs)\n",
    "        \n",
    "        # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –æ–±–∞ –∫—ç—à–∞\n",
    "        await self.semantic_cache.astore(prompt_text, response.content)\n",
    "        await self._exact_cache_set(exact_key, response)\n",
    "        \n",
    "        return {\"content\": response.content, \"usage\": response.response_metadata}\n",
    "    \n",
    "    def _normalize_prompt(self, messages: List[Dict]) -> str:\n",
    "        \"\"\"–ö–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–π —Ç–µ–∫—Å—Ç –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞\"\"\"\n",
    "        return \" | \".join([f\"{m['role']}: {m['content']}\" for m in messages])\n",
    "    \n",
    "    def _make_exact_key(self, messages: List[Dict], **kwargs) -> str:\n",
    "        payload = msgpack.packb({\"messages\": messages, **kwargs})\n",
    "        return f\"exact:{hashlib.sha256(payload).hexdigest()}\"\n",
    "    \n",
    "    async def _exact_cache_get(self, key: str) -> Dict[str, Any] | None:\n",
    "        data = await self.redis.get(key)\n",
    "        return msgpack.unpackb(data, raw=False) if data else None\n",
    "    \n",
    "    async def _exact_cache_set(self, key: str, response: Dict, ttl: int = 7200):\n",
    "        await self.redis.set(key, msgpack.packb(response), ex=ttl)\n",
    "\n",
    "# üß™ –¢–µ—Å—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∫—ç—à–∞\n",
    "async def test_semantic_cache():\n",
    "    cache = SemanticLLMCache(\"redis://localhost:6380\")\n",
    "    \n",
    "    # –ü–æ—Ö–æ–∂–∏–µ –∑–∞–ø—Ä–æ—Å—ã (—Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏)\n",
    "    queries = [\n",
    "        \"–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç Python async/await?\",\n",
    "        \"–û–±—ä—è—Å–Ω–∏ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ—Å—Ç—å –≤ Python\",\n",
    "        \"–ß—Ç–æ —Ç–∞–∫–æ–µ asyncio –≤ Python?\"\n",
    "    ]\n",
    "    \n",
    "    for i, q in enumerate(queries):\n",
    "        messages = [{\"role\": \"user\", \"content\": q}]\n",
    "        result = await cache.get_or_generate(messages)\n",
    "        print(result.keys())\n",
    "        print(f\"Q{i+1}: {result['response'][:100]}...\")\n",
    "        await asyncio.sleep(0.1)  # Rate limit\n",
    "\n",
    "await test_semantic_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfb5f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6aee99cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "REDIS_URL = \"redis://localhost:6380\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c009af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from redis.asyncio import Redis, ConnectionPool\n",
    "\n",
    "\n",
    "class LLMCache:\n",
    "    def __init__(self, redis_url=REDIS_URL):\n",
    "        self.redis_url = redis_url\n",
    "        self.pool = ConnectionPool(self.redis_url)\n",
    "        self.redis = Redis(connection_pool=self.pool)\n",
    "        self.default_ttl = 3600\n",
    "\n",
    "    def make_cache_key(self, messages):\n",
    "        payload = {\n",
    "            \"messages\": messages\n",
    "        }\n",
    "        key_hash = hashlib.sha256(payload).hexdigest()\n",
    "        return f\"llm:{key_hash}\"\n",
    "    \n",
    "    async def get(self, key):\n",
    "        data = await self.redis.get(key)\n",
    "        if data:\n",
    "            return data\n",
    "        return None\n",
    "    \n",
    "    async def set(self, key, response, ttl = None):\n",
    "        ttl = ttl or self.default_ttl\n",
    "        data = response\n",
    "        await self.redis.set(key, data, ex=ttl)\n",
    "\n",
    "    async def get_or_call(self, key, ttl = None):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86af2afa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
